link: https://h6jjzbhp2kjhb9azpqc2pu.streamlit.app/

Documentation for RAG-Enhanced Chatbot Application 

This document outlines the functionality and code structure of the RAG-enhanced chatbot application. 

Application Overview: 

This application utilizes the Retrieval Augmented Generation (RAG) technique to enhance chatbot responses with information extracted from uploaded documents. Users can upload PDF and DOCX files, and the application creates a vector database to store the text content. When a user asks a question, the application searches the vector database for relevant information and incorporates it into the prompt for a large language model (LLM) like ChatGPT. This allows the LLM to provide more informed and contextually relevant responses. 

Technology Stack: 

Python: The primary programming language for the application. 

Streamlit: Used for building the user interface and interactive elements. 

Databutton: Manages secrets and environment variables, like the OpenAI API key. 

LangChain: Provides tools for working with LLMs, including text splitting, document management, and vector stores. 

OpenAI: Provides the LLM (e.g., ChatGPT) for generating responses. 

FAISS: A library for efficient similarity search in vector spaces. 

PyPDF: Used for parsing and extracting text from PDF files. 

python-docx: Used for parsing and extracting text from DOCX files. 

Code Structure: 

requirements.txt: Lists the required Python packages and their versions. 

brain.py: Contains functions for: 

Parsing PDF and DOCX files and extracting text content. 

Converting extracted text into LangChain documents. 

Creating a FAISS vector store from the documents. 

Building a vector index for uploaded PDF and DOCX files. 

app.py: Contains the Streamlit application logic, including: 

Setting up the OpenAI API key. 

Defining the user interface with file upload functionality and chat input. 

Caching the vector database creation process. 

Defining the prompt template for the LLM, incorporating information from relevant documents. 

Performing similarity search in the vector database to find relevant information based on the user's question. 

Calling the LLM with streaming to display the response dynamically. 

Managing the chat history and prompt within the session state. 

Functionality: 

File Upload: Users can upload multiple PDF and DOCX files. 

Vector Database Creation: The application processes the uploaded files and creates a vector database of the text content. 

Question Answering: Users can ask questions in a chat interface. 

Contextual Responses: The application retrieves relevant information from the vector database and uses it to provide informed responses generated by the LLM. 

Streaming Output: The LLM response is displayed dynamically as it is generated. 

Additional Notes: 

The prompt_template in app.py can be customized to provide specific instructions or context to the LLM. 

The number of search results (k) used for retrieving relevant information can be adjusted based on the desired level of detail and context. 

The application assumes the OpenAI API key is stored securely using Databutton secrets. 

Future Improvements: 

Implement user authentication and document access control. 

Allow users to select specific documents for each query. 

Support additional file formats. 

Integrate with other LLMs. 

Explore different vector store options. 

Fine-tune the LLM for specific domains or tasks. 

I hope this documentation provides a clear understanding of the RAG-enhanced chatbot application. Please let me know if you have any further question 

 
